{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install --upgrade torch torchvision"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-04-22T07:16:27.175177Z","iopub.status.busy":"2022-04-22T07:16:27.174818Z","iopub.status.idle":"2022-04-22T07:16:30.2589Z","shell.execute_reply":"2022-04-22T07:16:30.25814Z","shell.execute_reply.started":"2022-04-22T07:16:27.175077Z"},"trusted":true},"outputs":[],"source":["#Importing Pytorch, OpenCV, Albemntations\n","import torch\n","import cv2\n","import albumentations as A\n","from glob import glob\n","from tqdm import tqdm\n","from torch.utils.data import Dataset, DataLoader, random_split\n","from albumentations.pytorch.transforms import ToTensorV2\n","from torchvision import models\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchmetrics import (Accuracy, ConfusionMatrix,)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-22T07:16:31.362435Z","iopub.status.busy":"2022-04-22T07:16:31.362122Z","iopub.status.idle":"2022-04-22T07:16:31.375433Z","shell.execute_reply":"2022-04-22T07:16:31.374361Z","shell.execute_reply.started":"2022-04-22T07:16:31.36238Z"},"trusted":true},"outputs":[],"source":["category = {\n","    'Apple': (\n","        0 , {\n","        'Apple_scab': 0,\n","        'Black_rot': 1,\n","        'Cedar_apple_rust': 2,\n","        'healthy': 3,\n","        }\n","    ),\n","    'Blueberry': (\n","        1, {\n","        'healthy': 4,\n","        }\n","    ),\n","    'Cherry': (\n","        2, {\n","            'Powdery_mildew': 5,\n","            'healthy': 6,\n","        }\n","    ),\n","    'Corn': (\n","        3, {\n","            'Cercospora_leaf_spot': 7,\n","            'Common_rust': 8,\n","            'Northern_Leaf_Blight': 9,\n","            'healthy': 10,\n","        }\n","    ),\n","    'Grape': (\n","        4, {\n","            'Black_rot': 11,\n","            'Esca': 12,\n","            'Leaf_blight': 13,\n","            'healthy': 14,\n","        }\n","    ),\n","    'Orange': (\n","        5, {\n","            'Haunglongbing': 15,\n","        }\n","    ),\n","    'Peach': (\n","        6, {\n","            'Bacterial_spot': 16,\n","            'healthy': 17,\n","        }\n","    ),\n","    'Pepper': (\n","        7, {\n","            'Bacterial_spot': 18,\n","            'healthy': 19\n","        }\n","    ),\n","    'Potato': (\n","        8, {\n","            'Early_blight': 20,\n","            'Late_blight': 21,\n","            'healthy': 22,\n","        }\n","    ),\n","    'Raspberry': (\n","        9, {\n","            'healthy': 23,\n","        }\n","    ),\n","    'Soybean': (\n","        10, {\n","            'healthy': 24,\n","        }\n","    ),\n","    'Squash': (\n","        11, {\n","            'Powdery_mildew': 25,\n","        }\n","    ),\n","    'Strawberry': (\n","        12, {\n","            'Leaf_scorch': 26,\n","            'healthy': 27,\n","        }\n","    ),\n","    'Tomato': (\n","        13, {\n","            'Bacterial_spot': 28,\n","            'Early_blight': 29,\n","            'Late_blight': 30,\n","            'Leaf_Mold': 31,\n","            'Septoria_leaf_spot': 32,\n","            'Spider_mites': 33,\n","            'Target_Spot': 34,\n","            'Yellow_Leaf_Curl_Virus': 35,\n","            'mosaic_virus': 36,\n","            'healthy': 37,\n","        }\n","    ),\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-22T07:16:31.912192Z","iopub.status.busy":"2022-04-22T07:16:31.911238Z","iopub.status.idle":"2022-04-22T07:16:31.922815Z","shell.execute_reply":"2022-04-22T07:16:31.921758Z","shell.execute_reply.started":"2022-04-22T07:16:31.912146Z"},"trusted":true},"outputs":[],"source":["class PlantDiseasesDataset(Dataset):\n","    def __init__(self, path, transform=None):\n","        self.files = glob(path, recursive=True)\n","        \n","        if transform is not None:\n","            self.transform = transform\n","        else:\n","            self.transform = A.Compose([\n","                A.Normalize(),\n","                ToTensorV2(),\n","            ])\n","        \n","    def __len__(self):\n","        return len(self.files)\n","    \n","    def __getitem__(self, idx):\n","        item = self.files[idx]\n","        \n","        fruit = None\n","        label = None\n","        \n","        for fruit_i in category.keys():\n","            if fruit_i in item:\n","                fruit = category[fruit_i]\n","                break\n","                \n","        for dis in fruit[1].keys():\n","            if dis in item:\n","                label = fruit[1][dis]\n","                break\n","\n","        img = cv2.imread(item)\n","        \n","        fruit_channel = torch.ones(1, img.shape[0], img.shape[1])\n","        fruit_channel *= fruit[0] / 13        \n","        \n","        img = self.transform(image=img)['image']\n","        \n","        img = torch.vstack([img, fruit_channel])\n","        \n","        if label is None or fruit is None:\n","            print(label, fruit)\n","        \n","        return img, fruit[0], label"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-22T07:16:32.480418Z","iopub.status.busy":"2022-04-22T07:16:32.480125Z","iopub.status.idle":"2022-04-22T07:16:32.488139Z","shell.execute_reply":"2022-04-22T07:16:32.48711Z","shell.execute_reply.started":"2022-04-22T07:16:32.480367Z"},"trusted":true},"outputs":[],"source":["class NeuralNet(nn.Module):\n","    def __init__(self, in_channels, num_classes):\n","        super(NeuralNet, self).__init__()\n","        self.in_channels = in_channels\n","        self.input_layer = nn.Sequential(\n","#                 nn.BatchNorm2d(in_channels),\n","                nn.Conv2d(in_channels, 3, 3, 1, 1)\n","        )\n","        \n","        self.efficientnet = models.efficientnet_b7(pretrained=True)\n","        \n","        self.last = nn.Sequential(\n","            nn.Linear(1000, 256),\n","            nn.ReLU(),\n","            nn.Linear(256, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, num_classes),\n","        )\n","        \n","    def forward(self, x,):\n","        if self.in_channels != 3:\n","            x = self.input_layer(x)\n","            \n","        x = self.efficientnet(x)\n","#         x = torch.cat([x, fruit])\n","        x = self.last(x)\n","        \n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-22T07:17:17.951507Z","iopub.status.busy":"2022-04-22T07:17:17.951205Z","iopub.status.idle":"2022-04-22T07:17:17.963952Z","shell.execute_reply":"2022-04-22T07:17:17.963225Z","shell.execute_reply.started":"2022-04-22T07:17:17.951474Z"},"trusted":true},"outputs":[],"source":["def train(model, loader, crit, optimizer, device):\n","    loop = tqdm(loader)\n","    \n","    losses = []\n","    \n","    for img, _, label in loop:\n","        img = img.to(device)\n","        label = label.to(device).long()\n","        \n","        preds = model(img)\n","        loss = crit(preds, label.view(-1))\n","        \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        loop.set_postfix({\n","            'loss': loss.item()\n","        })\n","        \n","        losses.append(loss.item())\n","        \n","    return losses\n","        \n","def valid(model, loader, crit, device):\n","    loop = tqdm(loader)\n","    \n","    acc, cmatrix = Accuracy(num_classes=38),  ConfusionMatrix(num_classes=38)\n","    losses = []\n","    \n","    for img, _, label in loop:\n","        img = img.to(device)\n","        label = label.to(device).long()\n","        \n","        preds = model(img)\n","        loss = crit(preds, label.view(-1))\n","        \n","#         preds\n","        preds = torch.softmax(preds, dim=1).cpu()\n","        label = label.cpu()\n","        acc.update(preds, label.view(-1))\n","#         avg_pre.update(preds, label.view(-1))\n","        cmatrix.update(preds, label.view(-1))\n","        \n","        loop.set_postfix({\n","            'loss': loss.item()\n","        })\n","        \n","        losses.append(loss.item())\n","        \n","    print(f\"Accuracy: {acc.compute()}\")\n","#     print(f\"Avg. Precision: {avg_pre.compute()}\")\n","    print(f\"Confusion Matrix:\")\n","    print(cmatrix.compute())\n","    \n","    return losses"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-22T07:16:57.214031Z","iopub.status.busy":"2022-04-22T07:16:57.213748Z","iopub.status.idle":"2022-04-22T07:17:02.78485Z","shell.execute_reply":"2022-04-22T07:17:02.784042Z","shell.execute_reply.started":"2022-04-22T07:16:57.214001Z"},"trusted":true},"outputs":[],"source":["NUM_EPOCHS = 5\n","LRN_RATE = 1e-5\n","BATCH_SIZE = 8\n","DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n","LOAD_MODEL = True\n","\n","crit = nn.CrossEntropyLoss()\n","model = NeuralNet(4, 38).to(DEVICE)\n","\n","if LOAD_MODEL:\n","    model.load_state_dict(torch.load('./model_checkpoint_1.pt')['model'])\n","\n","optimizer = optim.AdamW(model.parameters(), LRN_RATE)\n","data = PlantDiseasesDataset('../input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/*/*.JPG')\n","\n","train_len = len(data) - 5000\n","val_len = 5000\n","\n","train_set, val_set = random_split(data, [train_len, val_len])\n","train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n","val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_losses = []\n","val_losses = []\n","for epoch in range(NUM_EPOCHS):\n","    print(f'Epoch #{epoch}')\n","    print('Training')\n","    train_losses += train(model, train_loader, crit, optimizer, DEVICE)\n","    print('Validation')\n","    val_losses += valid(model, val_loader, crit, DEVICE)\n","    \n","    checkpoint = {\n","        'model' : model.state_dict(),\n","        'optimizer' : optimizer.state_dict(),\n","    }\n","    \n","    torch.save(checkpoint, f'model_checkpoint_{epoch}.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(train_losses)\n","plt.plot(val_losses)\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-22T07:17:21.758219Z","iopub.status.busy":"2022-04-22T07:17:21.757384Z","iopub.status.idle":"2022-04-22T07:18:25.398453Z","shell.execute_reply":"2022-04-22T07:18:25.395909Z","shell.execute_reply.started":"2022-04-22T07:17:21.758175Z"},"trusted":true},"outputs":[],"source":["_ = valid(model, val_loader, crit, DEVICE)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def predict(image):\n","    \"\"\"\n","\n","    \"\"\"\n","\n","    model = NeuralNet(4, 38)\n","    model.load_state_dict(torch.load('./model_checkpoint_1.pt')['model'])\n","    \n","    pred = torch.argmax(torch.softmax(model(image)))\n","\n","    prediction = None\n","\n","    return prediction\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
